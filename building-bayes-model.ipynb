{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, balanced_accuracy_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (4,6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df_final = pd.read_csv('./data/fire_frug_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_flair_type</th>\n",
       "      <th>author_patreon_flair</th>\n",
       "      <th>author_full</th>\n",
       "      <th>...</th>\n",
       "      <th>pwls</th>\n",
       "      <th>retr_on</th>\n",
       "      <th>score</th>\n",
       "      <th>stickied</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>tot_awards</th>\n",
       "      <th>upvote_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SMITBOMB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>False</td>\n",
       "      <td>t2_3yxsd0ki</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1643733499</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Lately, I’ve really been contemplating the pur...</td>\n",
       "      <td>1643733488</td>\n",
       "      <td>Do I really need to invest?</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Riffington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>False</td>\n",
       "      <td>t2_dyavg</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1643730749</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Fire</td>\n",
       "      <td>I can’t seem to find the step by step roadmap ...</td>\n",
       "      <td>1643730738</td>\n",
       "      <td>Savings planning roadmap</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1      author  \\\n",
       "0           0             0               0    SMITBOMB   \n",
       "1           1             1               1  Riffington   \n",
       "\n",
       "  author_flair_css_class author_flair_richtext author_flair_text  \\\n",
       "0                    NaN                    []               NaN   \n",
       "1                    NaN                    []               NaN   \n",
       "\n",
       "  author_flair_type  author_patreon_flair  author_full  ... pwls     retr_on  \\\n",
       "0              text                 False  t2_3yxsd0ki  ...    6  1643733499   \n",
       "1              text                 False     t2_dyavg  ...    6  1643730749   \n",
       "\n",
       "   score  stickied  subreddit  \\\n",
       "0      1     False       Fire   \n",
       "1      1     False       Fire   \n",
       "\n",
       "                                                text        time  \\\n",
       "0  Lately, I’ve really been contemplating the pur...  1643733488   \n",
       "1  I can’t seem to find the step by step roadmap ...  1643730738   \n",
       "\n",
       "                         title  tot_awards  upvote_r  \n",
       "0  Do I really need to invest?           0       1.0  \n",
       "1     Savings planning roadmap           0       1.0  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fire      19700\n",
       "Frugal    18650\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare target\n",
    "\n",
    "df_final['subreddit'] = df_final['subreddit'].map(lambda x: 1 if x=='Fire' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    19700\n",
       "0    18650\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['fullpost']= df_final['title'] + ' ' + df_final['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final['fullpost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_final['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=133)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbayes = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<28762x7800 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1394464 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cv = cvect.fit_transform(X_train)\n",
    "X_train_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28762, 7800)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cv = cvect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbayes.fit(X_train_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9969753858990404"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbayes.score(X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9975314651275989"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbayes.score(X_train_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(nbayes, X_test_cv, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '000k', ..., 'করল', 'মন', 'হচ'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bvocab = cvect.get_feature_names_out()\n",
    "bvocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000k</th>\n",
       "      <th>006</th>\n",
       "      <th>01</th>\n",
       "      <th>015</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>035</th>\n",
       "      <th>05</th>\n",
       "      <th>...</th>\n",
       "      <th>zestimate</th>\n",
       "      <th>zing</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoos</th>\n",
       "      <th>équation</th>\n",
       "      <th>করব</th>\n",
       "      <th>করল</th>\n",
       "      <th>মন</th>\n",
       "      <th>হচ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28757</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28758</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28759</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28760</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28761</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28762 rows × 7800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  000  000k  006  01  015  02  03  035  05  ...  zestimate  zing  \\\n",
       "0       0    0     0    0   0    0   0   0    0   0  ...          0     0   \n",
       "1       0    0     0    0   0    0   0   0    0   0  ...          0     0   \n",
       "2       0    0     0    0   0    0   0   0    0   0  ...          0     0   \n",
       "3       0    0     0    0   0    0   0   0    0   0  ...          0     0   \n",
       "4       0    4     0    0   0    0   0   0    0   0  ...          0     0   \n",
       "...    ..  ...   ...  ...  ..  ...  ..  ..  ...  ..  ...        ...   ...   \n",
       "28757   0    0     0    0   0    0   0   0    0   0  ...          0     0   \n",
       "28758   0    0     0    0   0    0   0   0    0   0  ...          0     0   \n",
       "28759   0    0     0    0   0    0   0   0    0   0  ...          0     0   \n",
       "28760   0    4     0    0   0    0   0   0    0   0  ...          0     0   \n",
       "28761   0    0     0    0   0    0   0   0    0   0  ...          0     0   \n",
       "\n",
       "       zone  zoom  zoos  équation  করব  করল  মন  হচ  \n",
       "0         0     0     0         0    0    0   0   0  \n",
       "1         0     0     0         0    0    0   0   0  \n",
       "2         0     0     0         0    0    0   0   0  \n",
       "3         0     0     0         0    0    0   0   0  \n",
       "4         0     0     0         0    0    0   0   0  \n",
       "...     ...   ...   ...       ...  ...  ...  ..  ..  \n",
       "28757     0     0     0         0    0    0   0   0  \n",
       "28758     0     0     0         0    0    0   0   0  \n",
       "28759     0     0     0         0    0    0   0   0  \n",
       "28760     0     0     0         0    0    0   0   0  \n",
       "28761     0     0     0         0    0    0   0   0  \n",
       "\n",
       "[28762 rows x 7800 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nboutp = pd.DataFrame(X_train_cv.A, columns=bvocab)\n",
    "nboutp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "just      15061\n",
       "like      13151\n",
       "money     13013\n",
       "years     12775\n",
       "year      12647\n",
       "don       10961\n",
       "want       9616\n",
       "time       9380\n",
       "work       9189\n",
       "ve         9002\n",
       "job        8324\n",
       "know       7773\n",
       "000        7621\n",
       "buy        7150\n",
       "need       6898\n",
       "good       6818\n",
       "people     6635\n",
       "make       6458\n",
       "new        6369\n",
       "income     6363\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nboutp.sum().sort_values(ascending=False)[:20]\n",
    "#top 20 words for both subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "coef = {'feature': cvect.get_feature_names_out(), \n",
    "        'coef': nbayes.coef_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "nbvar_outp = pd.DataFrame(nbayes.coef_).T.set_index(cvect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>-7.020834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>-5.125083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000k</th>\n",
       "      <td>-10.527098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>006</th>\n",
       "      <td>-10.415872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>-9.735970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>équation</th>\n",
       "      <td>-10.389897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>করব</th>\n",
       "      <td>-14.053458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>করল</th>\n",
       "      <td>-14.053458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>মন</th>\n",
       "      <td>-14.053458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>হচ</th>\n",
       "      <td>-14.053458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7800 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "00        -7.020834\n",
       "000       -5.125083\n",
       "000k     -10.527098\n",
       "006      -10.415872\n",
       "01        -9.735970\n",
       "...             ...\n",
       "équation -10.389897\n",
       "করব      -14.053458\n",
       "করল      -14.053458\n",
       "মন       -14.053458\n",
       "হচ       -14.053458\n",
       "\n",
       "[7800 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbvar_outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>years</th>\n",
       "      <td>-4.739659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>-4.780989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>-4.864342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>-4.953938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>-5.011063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>-5.125083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>-5.163737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>-5.166635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don</th>\n",
       "      <td>-5.173568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job</th>\n",
       "      <td>-5.233350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ve</th>\n",
       "      <td>-5.286908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>-5.288624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roth</th>\n",
       "      <td>-5.384231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>-5.386811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ira</th>\n",
       "      <td>-5.473854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>-5.488047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market</th>\n",
       "      <td>-5.521771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>-5.548338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401k</th>\n",
       "      <td>-5.558920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retirement</th>\n",
       "      <td>-5.580008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "years      -4.739659\n",
       "year       -4.780989\n",
       "just       -4.864342\n",
       "money      -4.953938\n",
       "like       -5.011063\n",
       "000        -5.125083\n",
       "work       -5.163737\n",
       "want       -5.166635\n",
       "don        -5.173568\n",
       "job        -5.233350\n",
       "ve         -5.286908\n",
       "time       -5.288624\n",
       "roth       -5.384231\n",
       "income     -5.386811\n",
       "ira        -5.473854\n",
       "people     -5.488047\n",
       "market     -5.521771\n",
       "know       -5.548338\n",
       "401k       -5.558920\n",
       "retirement -5.580008"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbvar_outp.sort_values(by=0, ascending=False)[:20]\n",
    "#top 20 words of importance indicating fire subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clocks</th>\n",
       "      <td>-14.053458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>portioned</th>\n",
       "      <td>-14.053458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>portions</th>\n",
       "      <td>-14.053458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>portrait</th>\n",
       "      <td>-14.053458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>portugal</th>\n",
       "      <td>-14.053458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cliff</th>\n",
       "      <td>-14.053458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positively</th>\n",
       "      <td>-14.053458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>possessions</th>\n",
       "      <td>-14.053458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clicking</th>\n",
       "      <td>-14.053458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>click</th>\n",
       "      <td>-14.053458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cliche</th>\n",
       "      <td>-14.053458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clearly</th>\n",
       "      <td>-14.053458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleared</th>\n",
       "      <td>-14.053458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clearance</th>\n",
       "      <td>-14.053458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pot</th>\n",
       "      <td>-14.053458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>potatoes</th>\n",
       "      <td>-14.053458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleanup</th>\n",
       "      <td>-14.053458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pound</th>\n",
       "      <td>-14.053458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>powder</th>\n",
       "      <td>-14.053458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>হচ</th>\n",
       "      <td>-14.053458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "clocks      -14.053458\n",
       "portioned   -14.053458\n",
       "portions    -14.053458\n",
       "portrait    -14.053458\n",
       "portugal    -14.053458\n",
       "cliff       -14.053458\n",
       "positively  -14.053458\n",
       "possessions -14.053458\n",
       "clicking    -14.053458\n",
       "click       -14.053458\n",
       "cliche      -14.053458\n",
       "clearly     -14.053458\n",
       "cleared     -14.053458\n",
       "clearance   -14.053458\n",
       "pot         -14.053458\n",
       "potatoes    -14.053458\n",
       "cleanup     -14.053458\n",
       "pound       -14.053458\n",
       "powder      -14.053458\n",
       "হচ          -14.053458"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbvar_outp.sort_values(by=0, ascending=False)[-20:]\n",
    "#bottom 20 words of importance indicating frugal subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline(steps=[('cvect',CountVectorizer()), ('nbayes', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first try on parameters\n",
    "params = {\n",
    "    'nbayes__alpha':[0.1, 2], \n",
    "    'cvect__ngram_range':[(1,2), (1,3)], \n",
    "    'cvect__max_df':[0.5, 0.7, 1]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search\n",
    "gs = GridSearchCV(pipe, param_grid=params, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "20 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1347, in fit_transform\n",
      "    X, self.stop_words_ = self._limit_features(\n",
      "  File \"C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1179, in _limit_features\n",
      "    raise ValueError(\n",
      "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [ 1.  1.  1.  1.  1.  1.  1.  1. nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('cvect', CountVectorizer()),\n",
       "                                       ('nbayes', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvect__max_df': [0.5, 0.7, 1],\n",
       "                         'cvect__ngram_range': [(1, 2), (1, 3)],\n",
       "                         'nbayes__alpha': [0.1, 2]})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second try on parameters\n",
    "params = {\n",
    "    'multinomialnb__alpha':[0.1, 2], \n",
    "    'countvectorizer__ngram_range':[(1,2), (1,3)], \n",
    "    'countvectorizer__max_df':[1, 5, 10]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search number 2\n",
    "gs = GridSearchCV(pipe, param_grid=params, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1347, in fit_transform\n",
      "    X, self.stop_words_ = self._limit_features(\n",
      "  File \"C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1179, in _limit_features\n",
      "    raise ValueError(\n",
      "ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\sarah\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "After pruning, no terms remain. Try a lower min_df or a higher max_df.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17848/3300874052.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    924\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 926\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    927\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    388\u001b[0m         \"\"\"\n\u001b[0;32m    389\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Pipeline\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"passthrough\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    346\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[1;31m# Fit or load from cache the current transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[0;32m    349\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fit_transform\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 893\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    894\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1345\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sort_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1347\u001b[1;33m             X, self.stop_words_ = self._limit_features(\n\u001b[0m\u001b[0;32m   1348\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_doc_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_doc_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_limit_features\u001b[1;34m(self, X, vocabulary, high, low, limit)\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[0mkept_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkept_indices\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1179\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   1180\u001b[0m                 \u001b[1;34m\"After pruning, no terms remain. Try a lower min_df or a higher max_df.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1181\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: After pruning, no terms remain. Try a lower min_df or a higher max_df."
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "gs.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1013f178bd8cc9c09c9a1bfa722153bff45040218b602b728b1ebb7cc8a12e61"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
